{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_embedding",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXK-x-thZOFW"
      },
      "source": [
        "data source: http://help.sentiment140.com/for-students\n",
        "\n",
        "learn bert NLP course https://www.udemy.com/course/bert-nlp-algorithm/learn/lecture/17347024#overview"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1D0fyeGEQERV"
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import re\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "import random\n",
        "\n",
        "\n",
        "from google.colab import drive"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irQ9IAB8OVe9",
        "outputId": "06c95189-4d2d-4f86-89aa-725c26a800b0"
      },
      "source": [
        "  !pip install bert-for-tf2"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert-for-tf2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/d3/820ccaf55f1e24b5dd43583ac0da6d86c2d27bbdfffadbba69bafe73ca93/bert-for-tf2-0.14.7.tar.gz (41kB)\n",
            "\r\u001b[K     |████████                        | 10kB 28.4MB/s eta 0:00:01\r\u001b[K     |████████████████                | 20kB 33.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 30kB 15.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 40kB 12.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 6.5MB/s \n",
            "\u001b[?25hCollecting py-params>=0.9.6\n",
            "  Downloading https://files.pythonhosted.org/packages/a4/bf/c1c70d5315a8677310ea10a41cfc41c5970d9b37c31f9c90d4ab98021fd1/py-params-0.9.7.tar.gz\n",
            "Collecting params-flow>=0.8.0\n",
            "  Downloading https://files.pythonhosted.org/packages/a9/95/ff49f5ebd501f142a6f0aaf42bcfd1c192dc54909d1d9eb84ab031d46056/params-flow-0.8.2.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.19.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.41.1)\n",
            "Building wheels for collected packages: bert-for-tf2, py-params, params-flow\n",
            "  Building wheel for bert-for-tf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bert-for-tf2: filename=bert_for_tf2-0.14.7-cp36-none-any.whl size=30537 sha256=a51045b03491db122b1188055df4b8b5b6d39d13dcac07b8e8b1c6f3a8686a1f\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/f8/e2/b98f79a6b8cc898d8e4102b83acb8a098df7d27500a2bac912\n",
            "  Building wheel for py-params (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-params: filename=py_params-0.9.7-cp36-none-any.whl size=7303 sha256=b04c30313f641aab46103bfcbbd2c4e357124e596df62503844a66d78ed83e56\n",
            "  Stored in directory: /root/.cache/pip/wheels/67/f5/19/b461849a50aefdf4bab47c4756596e82ee2118b8278e5a1980\n",
            "  Building wheel for params-flow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for params-flow: filename=params_flow-0.8.2-cp36-none-any.whl size=19474 sha256=4a57bda369c1bedb337ad28d155c353c2b78791c413b1be0717597107b191b53\n",
            "  Stored in directory: /root/.cache/pip/wheels/08/c8/7f/81c86b9ff2b86e2c477e3914175be03e679e596067dc630c06\n",
            "Successfully built bert-for-tf2 py-params params-flow\n",
            "Installing collected packages: py-params, params-flow, bert-for-tf2\n",
            "Successfully installed bert-for-tf2-0.14.7 params-flow-0.8.2 py-params-0.9.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRdXs311OvNf",
        "outputId": "55ca5d3a-ba01-40c8-c4e5-1c10bcc1900b"
      },
      "source": [
        "!pip install sentencepiece"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\r\u001b[K     |▎                               | 10kB 27.8MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 33.6MB/s eta 0:00:01\r\u001b[K     |▉                               | 30kB 21.6MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40kB 25.6MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51kB 23.9MB/s eta 0:00:01\r\u001b[K     |█▊                              | 61kB 26.2MB/s eta 0:00:01\r\u001b[K     |██                              | 71kB 28.0MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81kB 26.5MB/s eta 0:00:01\r\u001b[K     |██▋                             | 92kB 23.0MB/s eta 0:00:01\r\u001b[K     |███                             | 102kB 22.6MB/s eta 0:00:01\r\u001b[K     |███▎                            | 112kB 22.6MB/s eta 0:00:01\r\u001b[K     |███▌                            | 122kB 22.6MB/s eta 0:00:01\r\u001b[K     |███▉                            | 133kB 22.6MB/s eta 0:00:01\r\u001b[K     |████▏                           | 143kB 22.6MB/s eta 0:00:01\r\u001b[K     |████▍                           | 153kB 22.6MB/s eta 0:00:01\r\u001b[K     |████▊                           | 163kB 22.6MB/s eta 0:00:01\r\u001b[K     |█████                           | 174kB 22.6MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 184kB 22.6MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 194kB 22.6MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 204kB 22.6MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 215kB 22.6MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 225kB 22.6MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 235kB 22.6MB/s eta 0:00:01\r\u001b[K     |███████                         | 245kB 22.6MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 256kB 22.6MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 266kB 22.6MB/s eta 0:00:01\r\u001b[K     |████████                        | 276kB 22.6MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 286kB 22.6MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 296kB 22.6MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 307kB 22.6MB/s eta 0:00:01\r\u001b[K     |█████████                       | 317kB 22.6MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 327kB 22.6MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 337kB 22.6MB/s eta 0:00:01\r\u001b[K     |██████████                      | 348kB 22.6MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 358kB 22.6MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 368kB 22.6MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 378kB 22.6MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 389kB 22.6MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 399kB 22.6MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 409kB 22.6MB/s eta 0:00:01\r\u001b[K     |████████████                    | 419kB 22.6MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 430kB 22.6MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 440kB 22.6MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 450kB 22.6MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 460kB 22.6MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 471kB 22.6MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 481kB 22.6MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 491kB 22.6MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 501kB 22.6MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 512kB 22.6MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 522kB 22.6MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 532kB 22.6MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 542kB 22.6MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 552kB 22.6MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 563kB 22.6MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 573kB 22.6MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 583kB 22.6MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 593kB 22.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 604kB 22.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 614kB 22.6MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 624kB 22.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 634kB 22.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 645kB 22.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 655kB 22.6MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 665kB 22.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 675kB 22.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 686kB 22.6MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 696kB 22.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 706kB 22.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 716kB 22.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 727kB 22.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 737kB 22.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 747kB 22.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 757kB 22.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 768kB 22.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 778kB 22.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 788kB 22.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 798kB 22.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 808kB 22.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 819kB 22.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 829kB 22.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 839kB 22.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 849kB 22.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 860kB 22.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 870kB 22.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 880kB 22.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 890kB 22.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 901kB 22.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 911kB 22.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 921kB 22.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 931kB 22.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 942kB 22.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 952kB 22.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 962kB 22.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 972kB 22.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 983kB 22.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 993kB 22.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.0MB 22.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.0MB 22.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.0MB 22.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.0MB 22.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.0MB 22.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.1MB 22.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.1MB 22.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.1MB 22.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.1MB 22.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.1MB 22.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.1MB 22.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1MB 22.6MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.94\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V63VETbXO0SF"
      },
      "source": [
        "try:\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "import bert"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-r0rEPJPU-0",
        "outputId": "48d98901-9e31-49b3-a472-9d1f68b3c765"
      },
      "source": [
        "print(tf.version.VERSION)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cA5eChfpPtbG",
        "outputId": "2fd7c32f-d6ee-4a5d-f14f-77fb213eadc1"
      },
      "source": [
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMcJalSoQVLV"
      },
      "source": [
        "## Read data and load to dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_3HFiLVQfiK"
      },
      "source": [
        "columns = [\"sentiment\", \"id\", \"date\", \"query\", \"user\", \"text\"]"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-C5EuSnQH3o"
      },
      "source": [
        "data = pd.read_csv(\"/content/drive/MyDrive/BERT/sentiment_data/train.csv\",\n",
        "                   header=None, names=columns, engine=\"python\", encoding=\"latin1\")"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "3Ckb5y0MRGYQ",
        "outputId": "a9423bee-7ce1-4d23-b593-390f9eb19547"
      },
      "source": [
        "data.head(2)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>id</th>\n",
              "      <th>date</th>\n",
              "      <th>query</th>\n",
              "      <th>user</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810369</td>\n",
              "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>_TheSpecialOne_</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810672</td>\n",
              "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>scotthamilton</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentiment  ...                                               text\n",
              "0          0  ...  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
              "1          0  ...  is upset that he can't update his Facebook by ...\n",
              "\n",
              "[2 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGwnVzJKRTtY"
      },
      "source": [
        "data.drop([\"id\", \"date\", \"query\", \"user\"], inplace=True, axis=1)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEA7oPoiSogm"
      },
      "source": [
        "## DATA cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbhwG8qiSq1J"
      },
      "source": [
        "def clean_tweet(tweet):\n",
        "  tweet = BeautifulSoup(tweet, \"lxml\").get_text()\n",
        "  tweet = re.sub(r'@[A-Za-z0-9]+', ' ', tweet)\n",
        "  tweet = re.sub(r'https?://[A-Za-z0-9./]+', ' ', tweet)\n",
        "  # tweet = re.sub(r'[a-zA-Z\\.?!\\'\"]+', ' ', tweet)\n",
        "  tweet = re.sub(r'\\s+', ' ', tweet)\n",
        "  tweet = re.sub(r'^\\s+', '', tweet)\n",
        "  # lowercase everythin\n",
        "  tweet = tweet.lower()\n",
        "  return tweet"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iioQSlsvUTQR"
      },
      "source": [
        "data[\"clean_text\"] = data[\"text\"].apply(clean_tweet)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "FvRb0t1dU_64",
        "outputId": "2eb3365b-9d91-4381-f64c-3151b5f4b8aa"
      },
      "source": [
        "data.head(2)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text</th>\n",
              "      <th>clean_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "      <td>- awww, that's a bummer. you shoulda got david...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "      <td>is upset that he can't update his facebook by ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentiment  ...                                         clean_text\n",
              "0          0  ...  - awww, that's a bummer. you shoulda got david...\n",
              "1          0  ...  is upset that he can't update his facebook by ...\n",
              "\n",
              "[2 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjVZfweELvqX"
      },
      "source": [
        "data.loc[(data.sentiment==4), \"sentiment\"] = 1"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "7qEsikQAMImd",
        "outputId": "90aebceb-21f3-4716-81be-571707d90f08"
      },
      "source": [
        "data[data[\"sentiment\"]!=0].head(2)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text</th>\n",
              "      <th>clean_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>800000</th>\n",
              "      <td>1</td>\n",
              "      <td>I LOVE @Health4UandPets u guys r the best!!</td>\n",
              "      <td>i love u guys r the best!!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>800001</th>\n",
              "      <td>1</td>\n",
              "      <td>im meeting up with one of my besties tonight! ...</td>\n",
              "      <td>im meeting up with one of my besties tonight! ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        sentiment  ...                                         clean_text\n",
              "800000          1  ...                        i love u guys r the best!! \n",
              "800001          1  ...  im meeting up with one of my besties tonight! ...\n",
              "\n",
              "[2 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xka914eY0qES"
      },
      "source": [
        "## Tokenisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNRChRVU008R"
      },
      "source": [
        "FullTokeniser = bert.bert_tokenization.FullTokenizer\n",
        "bert_layer = hub.KerasLayer(\n",
        "    \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",\n",
        "    trainable=False)\n",
        "\n",
        "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy() \n",
        "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = FullTokeniser(vocab_file, do_lower_case)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPp3kWheJor3"
      },
      "source": [
        "we only use the first sentence for BERT inputs and so we add the CLS at the beginning and SEP at the end"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xG1ct8fJoIX"
      },
      "source": [
        "def encode_sentence(sent):\n",
        "  return [\"[CLS]\"] + tokenizer.tokenize(sent) + [\"[SEP]\"]"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kSXDX-m4n97"
      },
      "source": [
        "data[\"data_inputs\"] = data[\"clean_text\"].apply(encode_sentence)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "70usraHw42fy",
        "outputId": "0b93583f-779b-4c1b-d4e2-6eb482323c69"
      },
      "source": [
        "data.head(2)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text</th>\n",
              "      <th>clean_text</th>\n",
              "      <th>data_inputs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "      <td>- awww, that's a bummer. you shoulda got david...</td>\n",
              "      <td>[[CLS], -, aw, ##w, ##w, ,, that, ', s, a, bum...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "      <td>is upset that he can't update his facebook by ...</td>\n",
              "      <td>[[CLS], is, upset, that, he, can, ', t, update...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentiment  ...                                        data_inputs\n",
              "0          0  ...  [[CLS], -, aw, ##w, ##w, ,, that, ', s, a, bum...\n",
              "1          0  ...  [[CLS], is, upset, that, he, can, ', t, update...\n",
              "\n",
              "[2 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WogGMO5NG-zB"
      },
      "source": [
        "## dataset creation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3i40r00jy_jO"
      },
      "source": [
        "We need to create 3 different inputs for each sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WSAwREVzDyQ"
      },
      "source": [
        "def get_ids(tokens):\n",
        "  return tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "\n",
        "def get_mask(tokens):\n",
        "  return np.char.not_equal(tokens, \"[PAD]\").astype(int)\n",
        "\n",
        "\n",
        "def get_segments(tokens):\n",
        "  seg_ids = []\n",
        "  current_seg_id = 0\n",
        "  for tok in tokens:\n",
        "    seg_ids.append(current_seg_id)\n",
        "    if tok == \"[SEP]\":\n",
        "      current_seg_id = 1 - current_seg_id # toggle between 1 and 0\n",
        "  return seg_ids"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSGH2UffHMqO"
      },
      "source": [
        "We will create padded batches (so we pad sentences for each batch independently). This way we add the minimum number of padded tokens possible. For that we sort sentences by length, add padded_batches and then shuffle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXBae9qMIgaZ"
      },
      "source": [
        "data[\"len\"] = data[\"data_inputs\"].str.len()"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "1f9M6f0vIwje",
        "outputId": "d7bb11b7-b8d7-47e0-d1d3-babab4044d4d"
      },
      "source": [
        "data.head(2)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text</th>\n",
              "      <th>clean_text</th>\n",
              "      <th>data_inputs</th>\n",
              "      <th>len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "      <td>- awww, that's a bummer. you shoulda got david...</td>\n",
              "      <td>[[CLS], -, aw, ##w, ##w, ,, that, ', s, a, bum...</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "      <td>is upset that he can't update his facebook by ...</td>\n",
              "      <td>[[CLS], is, upset, that, he, can, ', t, update...</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentiment  ... len\n",
              "0          0  ...  29\n",
              "1          0  ...  31\n",
              "\n",
              "[2 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEbvqPpaVIL0"
      },
      "source": [
        "data[\"get_ids\"] = data[\"data_inputs\"].apply(get_ids)\n",
        "data[\"get_mask\"] = data[\"data_inputs\"].apply(get_mask)\n",
        "data[\"get_segments\"] = data[\"data_inputs\"].apply(get_segments)"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A57XV7JFWFuT"
      },
      "source": [
        "data[\"sorted_all\"] = data[[\"get_ids\", \"get_mask\", \"get_segments\", \"sentiment\"]]\\\n",
        "  .apply(lambda x: tuple([[x[0], x[1], x[2]], x[3]]), axis=1)"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mx6kunZ2tktR",
        "outputId": "304dabf2-02c3-4e15-ff7a-33e749a7eac8"
      },
      "source": [
        "print(data[\"sorted_all\"][0])"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "([[101, 1011, 22091, 2860, 2860, 1010, 2008, 1005, 1055, 1037, 26352, 5017, 1012, 2017, 2323, 2050, 2288, 2585, 12385, 1997, 2353, 2154, 2000, 2079, 2009, 1012, 1025, 1040, 102], array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1]), [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LboPZqaJNTPK"
      },
      "source": [
        "# do a random shuffling\n",
        "data = data.sample(frac=1).reset_index(drop=True)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hkf282DcNtsh"
      },
      "source": [
        "# sort the values\n",
        "data.sort_values(by=[\"len\"], inplace=True)"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "Kz2QnaFpOIeb",
        "outputId": "b4739bec-2f28-4d1e-c4bf-8688194f05c5"
      },
      "source": [
        "data.head(2)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text</th>\n",
              "      <th>clean_text</th>\n",
              "      <th>data_inputs</th>\n",
              "      <th>len</th>\n",
              "      <th>get_ids</th>\n",
              "      <th>get_mask</th>\n",
              "      <th>get_segments</th>\n",
              "      <th>sorted_all</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>535729</th>\n",
              "      <td>0</td>\n",
              "      <td>@whinstonr</td>\n",
              "      <td></td>\n",
              "      <td>[[CLS], [SEP]]</td>\n",
              "      <td>2</td>\n",
              "      <td>[101, 102]</td>\n",
              "      <td>[1, 1]</td>\n",
              "      <td>[0, 0]</td>\n",
              "      <td>([[101, 102], [1, 1], [0, 0]], 0)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>910981</th>\n",
              "      <td>1</td>\n",
              "      <td>@willbeblue</td>\n",
              "      <td></td>\n",
              "      <td>[[CLS], [SEP]]</td>\n",
              "      <td>2</td>\n",
              "      <td>[101, 102]</td>\n",
              "      <td>[1, 1]</td>\n",
              "      <td>[0, 0]</td>\n",
              "      <td>([[101, 102], [1, 1], [0, 0]], 1)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        sentiment          text  ... get_segments                         sorted_all\n",
              "535729          0   @whinstonr   ...       [0, 0]  ([[101, 102], [1, 1], [0, 0]], 0)\n",
              "910981          1  @willbeblue   ...       [0, 0]  ([[101, 102], [1, 1], [0, 0]], 1)\n",
              "\n",
              "[2 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPGujyfiOJa_"
      },
      "source": [
        "# we dont want the tweets that dont have data\n",
        "data = data[data[\"len\"]>7]"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "dysm2ijEOZ9e",
        "outputId": "ad3641e3-6744-42ab-fa3f-70f6736c9b40"
      },
      "source": [
        "data.head(2)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text</th>\n",
              "      <th>clean_text</th>\n",
              "      <th>data_inputs</th>\n",
              "      <th>len</th>\n",
              "      <th>get_ids</th>\n",
              "      <th>get_mask</th>\n",
              "      <th>get_segments</th>\n",
              "      <th>sorted_all</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>273658</th>\n",
              "      <td>1</td>\n",
              "      <td>@geoann07 ur welcome gurl god bless</td>\n",
              "      <td>ur welcome gurl god bless</td>\n",
              "      <td>[[CLS], ur, welcome, gu, ##rl, god, bless, [SEP]]</td>\n",
              "      <td>8</td>\n",
              "      <td>[101, 24471, 6160, 19739, 12190, 2643, 19994, ...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>([[101, 24471, 6160, 19739, 12190, 2643, 19994...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>837283</th>\n",
              "      <td>0</td>\n",
              "      <td>@colbylevi it's such a shame</td>\n",
              "      <td>it's such a shame</td>\n",
              "      <td>[[CLS], it, ', s, such, a, shame, [SEP]]</td>\n",
              "      <td>8</td>\n",
              "      <td>[101, 2009, 1005, 1055, 2107, 1037, 9467, 102]</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>([[101, 2009, 1005, 1055, 2107, 1037, 9467, 10...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        sentiment  ...                                         sorted_all\n",
              "273658          1  ...  ([[101, 24471, 6160, 19739, 12190, 2643, 19994...\n",
              "837283          0  ...  ([[101, 2009, 1005, 1055, 2107, 1037, 9467, 10...\n",
              "\n",
              "[2 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6EqlxDAVBdk"
      },
      "source": [
        "sorted_all = data.sorted_all.values"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WvnH_HnPx70"
      },
      "source": [
        "all_dataset = tf.data.Dataset.from_generator(lambda: sorted_all,\n",
        "                                             output_types=(tf.int32, tf.int32))"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqAl1BebQHTZ",
        "outputId": "dec79109-2c65-4093-f6e9-bd5eddec8b64"
      },
      "source": [
        "next(iter(all_dataset))"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(3, 8), dtype=int32, numpy=\n",
              " array([[  101, 24471,  6160, 19739, 12190,  2643, 19994,   102],\n",
              "        [    1,     1,     1,     1,     1,     1,     1,     1],\n",
              "        [    0,     0,     0,     0,     0,     0,     0,     0]],\n",
              "       dtype=int32)>, <tf.Tensor: shape=(), dtype=int32, numpy=1>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qM8YM0EmQSAl"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "all_batched = all_dataset.padded_batch(BATCH_SIZE,\n",
        "                                       padded_shapes=((3, None), ()),\n",
        "                                       padding_values=(0, 0))"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8TZiWQXTOuB"
      },
      "source": [
        "NB_BATCHES = math.ceil(len(sorted_all)/BATCH_SIZE)\n",
        "NB_BATCHES_TEST = NB_BATCHES // 10  \n",
        "all_batched.shuffle(NB_BATCHES)\n",
        "test_dataset = all_batched.take(NB_BATCHES_TEST)\n",
        "train_dataset = all_batched.skip(NB_BATCHES_TEST)"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2U0wSgd4V-rp"
      },
      "source": [
        "## Model building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DySUcqKne94H",
        "outputId": "bc60a692-75d8-4998-e08a-3d182caaa6d4"
      },
      "source": [
        "mysentence = [\"[CLS]\"] + tokenizer.tokenize(\"Roses are red.\") + [\"[SEP]\"]\n",
        "\n",
        "input_ids = get_ids(mysentence)\n",
        "input_mask = get_mask(mysentence)\n",
        "input_segments = get_segments(mysentence)\n",
        "\n",
        "inputs = tf.stack(\n",
        "    [\n",
        "      tf.cast(input_ids, dtype=tf.int32),\n",
        "      tf.cast(input_mask, dtype=tf.int32),\n",
        "      tf.cast(input_segments, dtype=tf.int32)\n",
        "    ], axis=0\n",
        ")\n",
        "inputs = tf.expand_dims(inputs, 0) # simulates a batch\n",
        "print(inputs.shape)\n",
        "bert_layer(inputs)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 3, 6)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-85-1b735e3c5cdb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# simulates a batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mbert_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_hub/keras_layer.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    235\u001b[0m       result = smart_cond.smart_cond(training,\n\u001b[1;32m    236\u001b[0m                                      \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m                                      lambda: f(training=False))\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0;31m# Unwrap dicts returned by signatures.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/smart_cond.py\u001b[0m in \u001b[0;36msmart_cond\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m     54\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mtrue_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfalse_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     return control_flow_ops.cond(pred, true_fn=true_fn, false_fn=false_fn,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_hub/keras_layer.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    235\u001b[0m       result = smart_cond.smart_cond(training,\n\u001b[1;32m    236\u001b[0m                                      \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m                                      lambda: f(training=False))\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0;31m# Unwrap dicts returned by signatures.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36m_call_attribute\u001b[0;34m(instance, *args, **kwargs)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_call_attribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 726\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/function_deserialization.py\u001b[0m in \u001b[0;36mrestored_function_body\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m         .format(_pretty_format_positional(args), kwargs,\n\u001b[1;32m    272\u001b[0m                 \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcrete_functions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m                 \"\\n\\n\".join(signature_descriptions)))\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m   \u001b[0mconcrete_function_objects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Could not find matching function to call loaded from the SavedModel. Got:\n  Positional arguments (3 total):\n    * Tensor(\"inputs:0\", shape=(1, 3, 6), dtype=int32)\n    * False\n    * None\n  Keyword arguments: {}\n\nExpected these arguments to match one of the following 4 option(s):\n\nOption 1:\n  Positional arguments (3 total):\n    * [TensorSpec(shape=(None, None), dtype=tf.int32, name='input_word_ids'), TensorSpec(shape=(None, None), dtype=tf.int32, name='input_mask'), TensorSpec(shape=(None, None), dtype=tf.int32, name='input_type_ids')]\n    * True\n    * None\n  Keyword arguments: {}\n\nOption 2:\n  Positional arguments (3 total):\n    * [TensorSpec(shape=(None, None), dtype=tf.int32, name='input_word_ids'), TensorSpec(shape=(None, None), dtype=tf.int32, name='input_mask'), TensorSpec(shape=(None, None), dtype=tf.int32, name='input_type_ids')]\n    * False\n    * None\n  Keyword arguments: {}\n\nOption 3:\n  Positional arguments (3 total):\n    * [TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/0'), TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/1'), TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/2')]\n    * True\n    * None\n  Keyword arguments: {}\n\nOption 4:\n  Positional arguments (3 total):\n    * [TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/0'), TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/1'), TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/2')]\n    * False\n    * None\n  Keyword arguments: {}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnDtRAzbWAZc"
      },
      "source": [
        "class DCNNBERTEmbedding(tf.keras.Model):\n",
        "  def __init__(self, nb_filters=50,\n",
        "               FFN_units=512, nb_classes=2, dropout_rate=0.1, name=\"dcnn\"):\n",
        "    super(DCNNBERTEmbedding, self).__init__(name=name)\n",
        "    \n",
        "    # self.embedding = layers.Embedding(vocab_size, emb_dim)\n",
        "    # instead of embedding we will use the bert layer\n",
        "    self.bert_layer = hub.KerasLayer(\n",
        "        \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",\n",
        "        trainable=False)\n",
        "\n",
        "    self.bigram = layers.Conv1D(filters=nb_filters, kernel_size=2,\n",
        "                                padding=\"valid\", activation=\"relu\")\n",
        "    self.trigram = layers.Conv1D(filters=nb_filters, kernel_size=3,\n",
        "                                 padding=\"valid\", activation=\"relu\")\n",
        "    self.fourgram = layers.Conv1D(filters=nb_filters, kernel_size=4,\n",
        "                                  padding=\"valid\", activation=\"relu\")\n",
        "    self.pool = layers.GlobalMaxPooling1D()\n",
        "    self.dense_1 = layers.Dense(units=FFN_units, activation=\"relu\")\n",
        "    self.dropout = layers.Dropout(rate=dropout_rate)\n",
        "    if nb_classes == 2:\n",
        "      self.last_dense = layers.Dense(units=1, activation=\"sigmoid\")\n",
        "    else:\n",
        "      self.last_dense = layers.Dense(units=nb_classes, activation=\"softmax\")\n",
        "\n",
        "  def embed_with_bert(self, all_tokens):\n",
        "    _, embs = self.bert_layer(\n",
        "        [all_tokens[:, 0, :],\n",
        "         all_tokens[:, 1, :],\n",
        "         all_tokens[:, 2, :]]\n",
        "    )\n",
        "    return embs\n",
        "\n",
        "  def call(self, inputs, training):\n",
        "    x = self.embed_with_bert(inputs)\n",
        "    x_1 = self.bigram(x)\n",
        "    x_1 = self.pool(x_1)\n",
        "    x_2 = self.trigram(x)\n",
        "    x_2 = self.pool(x_2)\n",
        "    x_3 = self.fourgram(x)\n",
        "    x_3 = self.pool(x_3)\n",
        "    merged = tf.concat([x_1, x_2, x_3], axis=-1) # (batch_size, 3*nb_filters)\n",
        "    merged = self.dense_1(merged)\n",
        "    merged = self.dropout(merged, training)\n",
        "    output = self.last_dense(merged)\n",
        "\n",
        "    return output"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxNjDCiG7l3D"
      },
      "source": [
        "## training ophase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UelH9Umu7nfJ"
      },
      "source": [
        "NB_FILTER = 100\n",
        "FFN_UNITS = 256\n",
        "NB_CLASSES = 2\n",
        "\n",
        "DROPOUT_RATE = 0.2\n",
        "\n",
        "NB_EPOCHS = 5"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxM2-FEP9dHi"
      },
      "source": [
        "dcnn = DCNNBERTEmbedding(nb_filters=NB_FILTER,\n",
        "            FFN_units=FFN_UNITS, nb_classes=NB_CLASSES,\n",
        "            dropout_rate=DROPOUT_RATE)"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwfylzXj-IMj"
      },
      "source": [
        "if NB_CLASSES == 2:\n",
        "  dcnn.compile(loss=\"binary_crossentropy\",\n",
        "               optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "else:\n",
        "  dcnn.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\",\n",
        "               metrics=[\"sparse_categorical_accuracy\"])"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tS0fINmeAOb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21bf35a1-1437-4c63-fa50-e6c22df53fcd"
      },
      "source": [
        "checkpoint_path = \"/content/drive/MyDrive/BERT/ckpt_bert_embedding\"\n",
        "\n",
        "ckpt = tf.train.Checkpoint(dcnn=dcnn)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=1)\n",
        "\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "  ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "  print(\"latest checkpoint restored!\")"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "latest checkpoint restored!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqhQN59jAU16"
      },
      "source": [
        "class MyCustomCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    ckpt_manager.save()\n",
        "    print(\"checkpoint saved at {}\".format(checkpoint_path))"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Hwh5VQ0U_BA",
        "outputId": "54b9381a-59f9-4b89-85bb-c765f04e60f8"
      },
      "source": [
        "dcnn.fit(train_dataset, epochs=NB_EPOCHS, callbacks=[MyCustomCallback()])"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "41039/41039 [==============================] - 2437s 59ms/step - loss: 0.3952 - accuracy: 0.8300\n",
            "checkpoint saved at /content/drive/MyDrive/BERT/ckpt_bert_embedding\n",
            "Epoch 2/5\n",
            "41039/41039 [==============================] - 2414s 58ms/step - loss: 0.3495 - accuracy: 0.8491\n",
            "checkpoint saved at /content/drive/MyDrive/BERT/ckpt_bert_embedding\n",
            "Epoch 3/5\n",
            "41039/41039 [==============================] - 2413s 58ms/step - loss: 0.3399 - accuracy: 0.8540\n",
            "checkpoint saved at /content/drive/MyDrive/BERT/ckpt_bert_embedding\n",
            "Epoch 4/5\n",
            "41039/41039 [==============================] - 2414s 58ms/step - loss: 0.3335 - accuracy: 0.8570\n",
            "checkpoint saved at /content/drive/MyDrive/BERT/ckpt_bert_embedding\n",
            "Epoch 5/5\n",
            "41039/41039 [==============================] - 2413s 58ms/step - loss: 0.3290 - accuracy: 0.8591\n",
            "checkpoint saved at /content/drive/MyDrive/BERT/ckpt_bert_embedding\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f9c78a0c3c8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huzRFNUfhmk-"
      },
      "source": [
        "## model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z42zbP0XhoV5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a740e2a5-64ba-4d20-c40c-4b95aeba0857"
      },
      "source": [
        "results = dcnn.evaluate(test_dataset)\n",
        "print(results)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4559/4559 [==============================] - 114s 25ms/step - loss: 0.3651 - accuracy: 0.8551\n",
            "[0.36508601903915405, 0.8551217317581177]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BciXWgp_humv"
      },
      "source": [
        "def get_prediction(sentence):\n",
        "  tokens = encode_sentence(sentence)\n",
        "\n",
        "  input_ids = get_ids(tokens)\n",
        "  input_mask = get_mask(tokens)\n",
        "  input_segments = get_segments(tokens)\n",
        "\n",
        "  inputs = tf.stack(\n",
        "      [\n",
        "       tf.cast(input_ids, dtype=tf.int32),\n",
        "       tf.cast(input_mask, dtype=tf.int32),\n",
        "       tf.cast(input_segments, dtype=tf.int32)\n",
        "      ], axis=0\n",
        "  )\n",
        "  inputs = tf.expand_dims(inputs, 0) # simulates a batch\n",
        "\n",
        "  output = dcnn(inputs, training=False)\n",
        "  \n",
        "  sentiment = math.floor(output * 2)\n",
        "\n",
        "  if sentiment == 0:\n",
        "    p = \"positive\"\n",
        "  else:\n",
        "    p = \"negative\"\n",
        "  print(\"output of the model: {}\".format(output))\n",
        "  print(\"predicted sentiment: {}\".format(p))"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5xfAkNIh-Qz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ae028d3-00c2-43ad-89f4-9ab61c482f6b"
      },
      "source": [
        "get_prediction(\"This movie was pretty interesting.\")"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "output of the model: [[0.69493526]]\n",
            "predicted sentiment: negative\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJJjFzemiplb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ca8c346-184e-49fa-f4dd-b976f08ddad3"
      },
      "source": [
        "get_prediction(\"This movie was shit\")"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "output of the model: [[0.08882713]]\n",
            "predicted sentiment: positive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCq-Osdcissp"
      },
      "source": [
        "  "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}